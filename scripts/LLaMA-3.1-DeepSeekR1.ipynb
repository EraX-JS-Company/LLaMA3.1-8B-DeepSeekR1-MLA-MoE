{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071ef5cd-97db-4182-b883-c673b37936ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e964f9-20d7-4e49-8586-e00e92e865df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import triton\n",
    "import triton.language as tl\n",
    "import copy\n",
    "from typing import Optional, Tuple, List, Dict, Any, Union\n",
    "from transformers.models.llama.modeling_llama import (\n",
    "    LlamaConfig,\n",
    "    LlamaModel, \n",
    "    LlamaForCausalLM,\n",
    "    LlamaDecoderLayer,\n",
    "    LlamaAttention,\n",
    "    LlamaMLP,\n",
    "    LlamaRMSNorm\n",
    ")\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233f6122-e786-4343-9c3c-95a80f9464b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "llama_model_path   = \"meta-llama/Llama-3.1-8B-Instruct\"\n",
    "llama_deepseek_dir = \"./llama_deepseek_8B_mla_moe\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57bff7af-646a-4afd-a13b-165374867663",
   "metadata": {},
   "source": [
    "# Convert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df3cbc2-8b81-4081-b169-1fb378439a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_deepseek_convert import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b5fa65-5fc8-4ea1-9954-8a32ed2f9214",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_model, new_config =  convert_llama_to_deepseek(\n",
    "    llama_model_path = llama_model_path, \n",
    "    output_dir = llama_deepseek_dir,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb35e713-3397-46e6-b3c6-38a4235ad060",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "  \"\"\"Counts the total number of trainable parameters in a PyTorch model.\n",
    "\n",
    "  Args:\n",
    "    model: A PyTorch model instance.\n",
    "\n",
    "  Returns:\n",
    "    The total number of trainable parameters in the model.\n",
    "  \"\"\"\n",
    "  total_params = sum(p.numel() for p in model.parameters())\n",
    "  trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "  return total_params, trainable_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f73b48e-6ce3-4ae4-9705-fa4be836cf08",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_params, trainable_params = count_parameters(new_model)\n",
    "total_params/1024/1024/1024, trainable_params # 12B --> 9B trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9402d6-3211-4753-908d-708d6252ff5c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(new_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd0de65-d307-41c2-ba88-d18602d68966",
   "metadata": {},
   "source": [
    "# Reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9952584e-447c-43e4-849b-e7734d3931c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_deepseek_model_test import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10c7c40-94bf-4e61-8a18-6cc781dc5d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = \"./llama_deepseek_8B_mla_moe\"\n",
    "inspect_only = False\n",
    "prompt = \"Tại sao bác Hồ được yêu quý ?\"\n",
    "max_new_tokens = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22329550-1687-4e49-9579-87442dd8b12d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch.distributed as dist\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "from datasets import load_dataset, Dataset\n",
    "from torch.utils.data import DataLoader, DistributedSampler\n",
    "import transformers\n",
    "from transformers import (\n",
    "    LlamaTokenizer, \n",
    "    LlamaForCausalLM, \n",
    "    Trainer, \n",
    "    TrainingArguments,\n",
    "    DataCollatorForLanguageModeling,\n",
    "    AutoTokenizer,\n",
    "    AutoModel\n",
    ")\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2,3\"\n",
    "\n",
    "from tqdm.notebook import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b7212d-e5a9-4751-9ba9-45d034551437",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    # Load the model and tokenizer\n",
    "    model, tokenizer = load_model(new_model, \"auto\")\n",
    "    \n",
    "    # Inspect model structure\n",
    "    logger.info(\"\\nInspecting model structure...\")\n",
    "    inspection_results = inspect_model_structure(model)\n",
    "    \n",
    "    logger.info(\"\\nModel Structure Inspection Results:\")\n",
    "    for key, value in inspection_results.items():\n",
    "        logger.info(f\"{key}: {value}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.error(f\"Error loading or testing model: {e}\")\n",
    "    import traceback\n",
    "    logger.error(traceback.format_exc())\n",
    "    sys.exit(1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a273f187-e6da-4a29-82e0-2e41eb42a208",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "inspection_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e82ba6-ea0e-487d-8e10-b9291db0d06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_params, trainable_params = count_parameters(model)\n",
    "total_params/1024/1024/1024, trainable_params # 12B --> 9B trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161ce7e4-ac20-4170-a756-bfd4d6a8eed1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6316c768-7882-45c7-950d-44f0ccdffefa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe7b45a-0d4c-4959-8f9b-2e64075b309a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
